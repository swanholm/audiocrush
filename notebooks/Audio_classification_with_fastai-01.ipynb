{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.transforms import RandomSplitter, get_files\n",
    "from fastai.data.core import DataLoaders\n",
    "from fastai.learner import Learner\n",
    "from audiocrush.data import *\n",
    "from fastai.data.block import CategoryBlock\n",
    "from fastai.data.transforms import parent_label \n",
    "from audiocrush.models.resnet_model import ResNet\n",
    "from audiocrush.models.models import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from fastai.callback.schedule import fit_one_cycle\n",
    "from fastai.losses import CrossEntropyLossFlat\n",
    "from fastai.metrics import accuracy\n",
    "\n",
    "from audiocrush.augment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('C:/Data/Instruments')\n",
    "\n",
    "fnames = get_audio_file_names(path)\n",
    "fnames[0]\n",
    "batch_tfms = [ # RandomNoise(),\n",
    "               RandomResample() ]\n",
    "\n",
    "dls = AudioDataLoaders.from_path_func(path, fnames, parent_label, valid_pct=0.2,\n",
    "                                  seed=None, item_tfms=None,\n",
    "                                  batch_tfms=batch_tfms)\n",
    "dls.bs = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.bs\n",
    "print(dls.after_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"DataLoaders device: {dls.device}\")\n",
    "print(dls.after_batch)\n",
    "# dls.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"DataLoaders device: {dls.device}\")\n",
    "print(dls.after_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvModelSimple3regu(num_classes=4)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = 5e-6\n",
    "lr # = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(lr_max=lr, n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(lr_max=lr, n_epoch=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.interpret import ClassificationInterpretation\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "\n",
    "\n",
    "interp.plot_top_losses(k=10)\n",
    "losses,idxs = interp.top_losses()\n",
    "\n",
    "interp.vocab\n",
    "interp.print_classification_report()\n",
    "interp.top_losses(k=10)\n",
    "print(interp.most_confused(min_val=5))\n",
    "\n",
    "interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
    "\n",
    "\n",
    "print(dls.valid_ds.items[36])\n",
    "print(losses.shape,idxs.shape)\n",
    "len(dls.valid_ds)==len(losses)==len(idxs)\n",
    "\n",
    "dls.show_batch()\n",
    "\n",
    "interp.show_results(idxs=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], nrows=2, ncols=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb, yb = dls.one_batch()\n",
    "print(xb.shape, yb.shape)\n",
    "print(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, targs = learn.get_preds()\n",
    "decoded_preds = preds.argmax(dim=1)\n",
    "\n",
    "print(decoded_preds.shape, targs.shape) \n",
    "print(decoded_preds, targs) \n",
    "\n",
    "xb, yb = learn.dls.valid.one_batch()\n",
    "print(xb.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(lr_max=lr, n_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "dls.bs = 128\n",
    "print(dls.bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(lr_max=lr, n_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('ConvModelSimple3regu-drums-02')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.predict(Path(\"c:\\\\Data\\\\Special-validation\\\\fb\\\\snare-01.wav\")))\n",
    "print(learn.dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (learn.get_preds(with_decoded=False))\n",
    "# a = torch.softmax(a, dim=1)\n",
    "# a = a.sum(dim=1)\n",
    "for tensor in a:\n",
    "    print(tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.cbs)\n",
    "print(learn.dls.vocab)\n",
    "print(learn.dls.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (learn.get_preds(with_decoded=True, with_input=True))\n",
    "# a = torch.softmax(a, dim=1)\n",
    "# a = a.sum(dim=1)\n",
    "for tensor in a:\n",
    "    print(tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = learn.get_preds()\n",
    "# a, b = a.type(torch.FloatTensor), b.type(torch.LongTensor)\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.torch_core import flatten_check\n",
    "flatten_check(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "preds, targs = a.argmax(dim=1), b  # If your predictions are logits\n",
    "print(confusion_matrix(targs, preds))\n",
    "print(classification_report(targs, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crush",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
